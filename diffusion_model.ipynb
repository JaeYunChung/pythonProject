{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"19-Q2rjiAuAh4fxZyFU2lto7TJXKCKG1K","authorship_tag":"ABX9TyNnOjprwJvEXvMkXR6TTQ7o"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import  matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","import math\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import(\n","    layers,\n","    models,\n","    optimizers,\n","    utils,\n","    callbacks,\n","    metrics,\n","    losses,\n","    activations,\n",")"],"metadata":{"id":"8Y0kAlejTL4e","executionInfo":{"status":"ok","timestamp":1731773308200,"user_tz":-540,"elapsed":5047,"user":{"displayName":"ᄋᄋ","userId":"18127923139488471666"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"HJbFkOX7TIYh","executionInfo":{"status":"ok","timestamp":1731773311367,"user_tz":-540,"elapsed":412,"user":{"displayName":"ᄋᄋ","userId":"18127923139488471666"}}},"outputs":[],"source":["IMAGE_SIZE=64\n","BATCH_SIZE=64\n","DATASET_REPETITION=5\n","LOAD_MODEL=False\n","\n","NOISE_EMBEDDING_SIZE=32\n","PLOT_DIFFUSION_STEPS=20\n","\n","EMA=0.99\n","LEARNING_RATE=1e-3\n","WEIGHT_DECAY=1e-4\n","EPOCHS=50"]},{"cell_type":"code","source":["!wget https://raw.githubusercontent.com/rickiepark/Generative_Deep_Learning_2nd_Edition/main/notebooks/utils.py\n","!mkdir -p notebooks\n","!mv utils.py notebooks\n","# output 디렉토리를 만듭니다.\n","!mkdir output\n","!mkdir model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ovhBzRWE4Mfy","executionInfo":{"status":"ok","timestamp":1731773314143,"user_tz":-540,"elapsed":1134,"user":{"displayName":"ᄋᄋ","userId":"18127923139488471666"}},"outputId":"9cdc820b-8a28-4855-8c13-834b2f831718"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-11-16 16:08:37--  https://raw.githubusercontent.com/rickiepark/Generative_Deep_Learning_2nd_Edition/main/notebooks/utils.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 771 [text/plain]\n","Saving to: ‘utils.py’\n","\n","utils.py            100%[===================>]     771  --.-KB/s    in 0s      \n","\n","2024-11-16 16:08:38 (41.5 MB/s) - ‘utils.py’ saved [771/771]\n","\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","files.upload()\n","!mkdir ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","!kaggle datasets download -d nunenuh/pytorch-challange-flower-dataset\n","!unzip -q pytorch-challange-flower-dataset.zip\n","!mkdir output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":227},"id":"cIzFoDqY8_JW","executionInfo":{"status":"ok","timestamp":1731773331356,"user_tz":-540,"elapsed":13737,"user":{"displayName":"ᄋᄋ","userId":"18127923139488471666"}},"outputId":"0eebb50c-992d-4ca4-b076-5b71b5274f34"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-08c7e842-1c3d-425a-a7b9-50057d472c1f\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-08c7e842-1c3d-425a-a7b9-50057d472c1f\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving kaggle (1).json to kaggle (1).json\n","cp: cannot stat 'kaggle.json': No such file or directory\n","chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n","Dataset URL: https://www.kaggle.com/datasets/nunenuh/pytorch-challange-flower-dataset\n","License(s): CC0-1.0\n","Downloading pytorch-challange-flower-dataset.zip to /content\n","100% 330M/330M [00:01<00:00, 219MB/s]\n","100% 330M/330M [00:01<00:00, 193MB/s]\n","mkdir: cannot create directory ‘output’: File exists\n"]}]},{"cell_type":"code","source":["train_data = utils.image_dataset_from_directory(\n","    \"./dataset/\",\n","    labels=None,\n","    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n","    batch_size=None,  # 데이터를 한번에 로드\n","    shuffle=True,\n","    seed=42,\n","    interpolation=\"bilinear\",  #주변 4개의 픽셀을 선형보간\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ZPuS0lE90lO","executionInfo":{"status":"ok","timestamp":1731773338513,"user_tz":-540,"elapsed":4383,"user":{"displayName":"ᄋᄋ","userId":"18127923139488471666"}},"outputId":"11b5496e-8678-40be-d478-0c9f3a682345"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 8189 files.\n"]}]},{"cell_type":"code","source":["def preprocessing(img):\n","  img = tf.cast(img, \"float32\")/255.0  # 0-1 값의 소수로 변환\n","  return img\n","\n","train = train_data.map(lambda x:preprocessing(x))\n","trian = train.repeat(DATASET_REPETITION) # 크기 DATASET_REPITITION만큼 복사\n","train = train.batch(BATCH_SIZE, drop_remainder=True)"],"metadata":{"id":"57ga3AwD9XYE","executionInfo":{"status":"ok","timestamp":1731773340143,"user_tz":-540,"elapsed":269,"user":{"displayName":"ᄋᄋ","userId":"18127923139488471666"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def offset_cosine_diffusion_schedule(diffusion_times):\n","  min_signal_rate= 0.2\n","  max_signal_rate= 0.95\n","  start_angle = tf.acos(max_signal_rate)\n","  end_angle = tf.acos(min_signal_rate)\n","\n","  diffusion_angles = start_angle + diffusion_times*(end_angle - start_angle)\n","  signal_rates = tf.cos(diffusion_angles)\n","  noise_rates = tf.sin(diffusion_angles)\n","\n","  return signal_rates, noise_rates"],"metadata":{"id":"o8-T-NwH-LNW","executionInfo":{"status":"ok","timestamp":1731773342281,"user_tz":-540,"elapsed":290,"user":{"displayName":"ᄋᄋ","userId":"18127923139488471666"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# 사인파 임베딩\n","from keras.utils import register_keras_serializable\n","\n","@register_keras_serializable(package=\"Custom\")\n","def sinusoidal_embedding(x): # x 차원 (1, 1, 1, 1)\n","  frequencies = tf.exp(\n","      tf.linspace(\n","          tf.math.log(1.0), tf.math.log(1000.0), NOISE_EMBEDDING_SIZE//2,\n","          )  # ln1 ~ ln1000 을 16으로 분할\n","      )\n","  angular_speeds = 2.0 * math.pi * frequencies  # 차원 (16, )\n","  embeddings = tf.concat([tf.sin(angular_speeds*x), (tf.cos(angular_speeds*x))], axis=3)\n","   # 곱할 때 브로드캐스팅 사용됨\n","   # embeddings 차원 concat((1, 1, 1, 16) + 1, 1, 1, 16) -> (1, 1, 2, 16)\n","  return embeddings"],"metadata":{"id":"nAn1YkqWDHqm","executionInfo":{"status":"ok","timestamp":1731773346419,"user_tz":-540,"elapsed":281,"user":{"displayName":"ᄋᄋ","userId":"18127923139488471666"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["embedding_list=[]\n","for y in np.arange(0, 1, 0.01):\n","  embedding_list.append(sinusoidal_embedding(np.array([[[[y]]]]))[0][0][0]) # (2, 16) 차원 요소 추가\n","embedding_array = np.array(np.transpose(embedding_list))\n","# embedding_array 차원 : (100, 2, 16) -> (16, 100, 2)\n","# 임베딩 배열에서 2요소는 0부터 1까지의 값을 가짐 & 2요소는 특정 노이즈 분산"],"metadata":{"id":"uYfUbUjLOimk","executionInfo":{"status":"ok","timestamp":1731773351609,"user_tz":-540,"elapsed":3065,"user":{"displayName":"ᄋᄋ","userId":"18127923139488471666"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["\"\"\"잔차 블록\n","스킵 연결을 사용하는데 그레디언트 소실과 성능저하를 막고 신경망을 더 깊게 만들 수 있음\n","스킵연결이란 컨볼루션을 진행하기 전과 후의 이미지 요소들의 값들을 더하는 것이다.\n","즉 학습되기 이전의 이미지를 더해주므로서 그레디언트 소실을 예방한다.\"\"\"\n","def ResidualBlock(width):\n","  def apply(x):\n","    input_width = x.shape[3]\n","    if input_width == width:\n","      residual = x\n","    else:\n","      residual = layers.Conv2D(width, kernel_size=1)(x)\n","      # 깊이가 width와 다르다면 깊이를 1로 만들어 브로드캐스팅을 한다\n","    x = layers.BatchNormalization(center=False, scale=False)(x) # 정규화\n","    x = layers.Conv2D(width, kernel_size = 3, padding= 'same', activation= activations.swish)(x)\n","    x = layers.Conv2D(width, kernel_size = 3, padding = 'same')(x)\n","    # 크기 유지하면서 깊이는 width로 2번 컨볼루션 진행\n","    x = layers.Add()([x, residual])\n","    return x\n","  return apply"],"metadata":{"id":"1d2g6aC7Q8HF","executionInfo":{"status":"ok","timestamp":1731773353564,"user_tz":-540,"elapsed":370,"user":{"displayName":"ᄋᄋ","userId":"18127923139488471666"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["\"\"\"block_depth만큼 스킵연결을 수행하고 Upsampling과 연결할 이미지를 저장한다.\n","    또한 이미지의 크기를 줄여서 특성이미지를 생성한다. \"\"\"\n","def DownBlock(width, block_depth):\n","  def apply(x):\n","    x, skips = x\n","    for _ in range(block_depth):\n","      x = ResidualBlock(width)(x)\n","      skips.append(x) # UpSampling에서 concatenate할 이미지 저장\n","    x = layers.AveragePooling2D(pool_size=2)(x)\n","    return x\n","  return apply"],"metadata":{"id":"MErjXgmipMyq","executionInfo":{"status":"ok","timestamp":1731773356191,"user_tz":-540,"elapsed":292,"user":{"displayName":"ᄋᄋ","userId":"18127923139488471666"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["\"\"\"Upsampling을 하여 pred nosie를 찾는다. skips.pop을 수행하여 이전 이미지와 연결한다 \"\"\"\n","def UpBlock(width, block_depth):\n","  def apply(x):\n","    x, skips = x\n","    x = layers.UpSampling2D(size=2, interpolation=\"bilinear\")(x) # 선형보간법으로 Upsampling\n","    for _ in range(block_depth):\n","      x = layers.Concatenate()([x, skips.pop()])\n","      x = ResidualBlock(width)(x)\n","    return x\n","  return apply"],"metadata":{"id":"vvQBOsG0q0Z6","executionInfo":{"status":"ok","timestamp":1731773358891,"user_tz":-540,"elapsed":311,"user":{"displayName":"ᄋᄋ","userId":"18127923139488471666"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["\"\"\"unet 구축\"\"\"\n","\n","# noisy 이미지 입력\n","noisy_images = layers.Input(shape= (IMAGE_SIZE, IMAGE_SIZE, 3))\n","x = layers.Conv2D(32, kernel_size= 1)(noisy_images)\n","\n","#  noise_variance 값에서 사인파 인베딩의 값\n","noise_variances = layers.Input(shape= (1, 1, 1))\n","noise_embedding = layers.Lambda(sinusoidal_embedding)(noise_variances) # 크기 = (1, 1, 32)\n","noise_embedding = layers.UpSampling2D(size=IMAGE_SIZE, interpolation=\"nearest\")(noise_embedding)\n","\n","# 노이즈 이미지와 노이즈 분산값을 연결\n","x = layers.Concatenate()([x, noise_embedding])\n","\n","skips = []\n","\n","x = DownBlock(32, block_depth=2)([x, skips])\n","x = DownBlock(64, block_depth=2)([x, skips])\n","x = DownBlock(96, block_depth=2)([x, skips])\n","\n","x = ResidualBlock(128)(x)\n","x = ResidualBlock(128)(x)\n","\n","x = UpBlock(96, block_depth=2)([x, skips])\n","x = UpBlock(64, block_depth=2)([x, skips])\n","x = UpBlock(32, block_depth=2)([x, skips])\n","\n","x = layers.Conv2D(3, kernel_size=1, kernel_initializer=\"zeros\")(x)\n","unet = models.Model([noisy_images, noise_variances], x, name=\"unet\")"],"metadata":{"id":"McGoXuPNrvkO","executionInfo":{"status":"ok","timestamp":1731773364514,"user_tz":-540,"elapsed":2918,"user":{"displayName":"ᄋᄋ","userId":"18127923139488471666"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["\n","class DiffusionModel(models.Model):\n","  def __init__(self):\n","    super().__init__()\n","    self.normalizer = layers.Normalization()\n","    self.network = unet\n","    self.ema_network = models.clone_model(self.network)\n","    self.diffusion_schedule = offset_cosine_diffusion_schedule\n","\n","  def compile(self, **kwargs):\n","    super().compile(**kwargs)\n","    self.noise_loss_tracker = metrics.Mean(name = \"n_loss\")\n","\n","  @property\n","  def metrics(self):\n","    return [self.noise_loss_tracker]\n","\n","  # 잡음 제거 예상 이미지에 잡음을 첨가하여 새로운 이미지를 생성한다.\n","  def denormalize(self, images): # images <- pred_images\n","    images = self.normalizer.mean + images*self.normalizer.variance**0.5 # 초기 잡은 생성\n","    return tf.clip_by_value(images, 0.0, 1.0) # 0-1 사이의 값을 가진 이미지 생성\n","\n","  # noise 예측, 초기 이미지 예측\n","  def denoise(self, noisy_images, noise_rates, signal_rates, training):\n","  # noise_rates, signal_rates <- offset_cosine_diffusion_schedule\n","    if training:\n","      network = self.network  #unet을 이용하여 pred_noise 도출\n","    else:\n","      network = self.ema_network\n","    pred_noises = network([noisy_images, noise_rates**2], training = training)\n","    pred_images = (noisy_images - noise_rates*pred_noises) / signal_rates\n","    \"\"\"noisy_images = signal_rates * pred_images + noise_rates * pred_noise\"\"\"\n","    return pred_noises, pred_images\n","\n","  # 노이즈를 정확도를 높여서 초기 이미지를 더 정교하게 예측하여 반환한다.\n","  def reverse_diffusion(self, initial_noise, diffusion_steps):\n","    num_images = initial_noise.shape[0] # batch size\n","    step_size = 1.0 / diffusion_steps # diffusion_steps = PLOT_DIFFUSION_STEPS = 20\n","    current_images = initial_noise\n","    for step in range(diffusion_steps):\n","      diffusion_times = tf.ones((num_images, 1, 1, 1)) - step * step_size\n","      noise_rates, signal_rates  = self.diffusion_schedule(diffusion_times) # offset_cosine_diffusion_schedule\n","      pred_noises, pred_images = self.denoise(current_images, noise_rates, signal_rates, training = False)\n","      # n 번째 노이즈 이미지로부터 pred_noise와 pred_image를 얻음\n","      next_diffusion_times = diffusion_times - step_size\n","      next_noise_rates, next_image_rates = self.diffusion_schedule(next_diffusion_times)\n","      current_images = next_image_rates * pred_images + next_noise_rates * pred_noises\n","      # 예측된 이미지로부터 n - 1번째 노이즈 이미지를 얻음\n","    return pred_images\n","\n","    \"\"\" n 번째 이미지로부터 초기 이미지를 예측하고 예측한 이미지는 n - 1번째 노이즈 이미지를 예측하고\n","      다시 이를 이용하여 n - 2 ...을 반복하면서 노이즈 예측의 정확성을 점진적으로 높여 pred_images\n","      를 얻는다.\"\"\"\n","\n","  def generate(self, num_images, diffusion_steps, initial_noise=None):\n","    if initial_noise is None:\n","      initial_noise = tf.random.normal(shape=(num_images, IMAGE_SIZE, IMAGE_SIZE, 3))\n","      # 초기 노이즈가 존재하지 않는 경우 노이즈를 랜덤한 값으로 생성한다.\n","    generated_images = self.reverse_diffusion(initial_noise, diffusion_steps)\n","    generated_images = self.denormalize(generated_images)\n","    return generated_images\n","\n","  def train_step(self, images):\n","    images = self.normalizer(images, training=True)\n","    noises = tf.random.normal(shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, 3))\n","\n","    diffusion_times = tf.random.uniform(shape=(BATCH_SIZE, 1, 1, 1), minval = 0.0, maxval = 1.0)\n","    noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n","    noisy_images = signal_rates * images + noise_rates * noises # 노이즈 이미지 생성\n","\n","    \"\"\"노이즈 예측 오차 학습\"\"\"\n","    with tf.GradientTape() as tape:\n","      pred_noises, pred_images = self.denoise(noisy_images, noise_rates, signal_rates, training=True)\n","      noise_loss = self.loss(noises, pred_noises)\n","\n","    gradients = tape.gradient(noise_loss, self.network.trainable_weights)\n","    self.optimizer.apply_gradients(zip(gradients, self.network.trainable_weights))\n","    self.noise_loss_tracker.update_state(noise_loss)\n","\n","    for weight, ema_weight in zip(self.network.weights, self.ema_network.weights):\n","      ema_weight.assign(EMA * ema_weight + (1-EMA)*weight)\n","    return {m.name: m.result() for m in self.metrics}\n","\n","  def test_step(self, images):\n","        images = self.normalizer(images, training=False)\n","        noises = tf.random.normal(shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, 3))\n","        diffusion_times = tf.random.uniform(\n","            shape=(BATCH_SIZE, 1, 1, 1), minval=0.0, maxval=1.0\n","        )\n","        noise_rates, signal_rates = self.diffusion_schedule(diffusion_times)\n","        noisy_images = signal_rates * images + noise_rates * noises\n","        pred_noises, pred_images = self.denoise(\n","            noisy_images, noise_rates, signal_rates, training=False\n","        )\n","        noise_loss = self.loss(noises, pred_noises)\n","        self.noise_loss_tracker.update_state(noise_loss)\n","\n","        return {m.name: m.result() for m in self.metrics}\n",""],"metadata":{"id":"35jYG1cv8Rwq","executionInfo":{"status":"ok","timestamp":1731773495693,"user_tz":-540,"elapsed":352,"user":{"displayName":"ᄋᄋ","userId":"18127923139488471666"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["ddm = DiffusionModel()\n","ddm.normalizer.adapt(train)"],"metadata":{"id":"BD2qJXNWc5jT","executionInfo":{"status":"ok","timestamp":1731773511684,"user_tz":-540,"elapsed":10801,"user":{"displayName":"ᄋᄋ","userId":"18127923139488471666"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["if LOAD_MODEL:\n","    ddm.built = True\n","    ddm.load_weights(\"./checkpoint/checkpoint.weights.h5\")"],"metadata":{"id":"YQacyJovqONF","executionInfo":{"status":"ok","timestamp":1731773515763,"user_tz":-540,"elapsed":538,"user":{"displayName":"ᄋᄋ","userId":"18127923139488471666"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.optimizers import Adam\n","ddm.compile(\n","    optimizer=optimizers.Adam(\n","        learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n","    ),\n","    loss=losses.mean_absolute_error,\n",")"],"metadata":{"id":"scu95PeIqPct","executionInfo":{"status":"ok","timestamp":1731773517915,"user_tz":-540,"elapsed":400,"user":{"displayName":"ᄋᄋ","userId":"18127923139488471666"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["sns.set_palette('colorblind')\n","from notebooks.utils import display, sample_batch"],"metadata":{"id":"3YEjgD4AxbSR","executionInfo":{"status":"ok","timestamp":1731773984511,"user_tz":-540,"elapsed":420,"user":{"displayName":"ᄋᄋ","userId":"18127923139488471666"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# 훈련을 실행하고 생성된 이미지를 주기적으로 출력합니다.\n","model_checkpoint_callback = callbacks.ModelCheckpoint(\n","    filepath=\"./checkpoint/checkpoint.weights.h5\",\n","    save_weights_only=True,\n","    save_freq=\"epoch\",\n","    verbose=0,\n",")\n","\n","tensorboard_callback = callbacks.TensorBoard(log_dir=\"./logs\")\n","\n","\n","class ImageGenerator(callbacks.Callback):\n","    def __init__(self, num_img):\n","        self.num_img = num_img\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        generated_images = self.model.generate(\n","            num_images=self.num_img,\n","            diffusion_steps=PLOT_DIFFUSION_STEPS,\n","        ).numpy()\n","        display(\n","            generated_images,\n","            save_to=\"./output/generated_img_%03d.png\" % (epoch),\n","        )\n","\n","\n","image_generator_callback = ImageGenerator(num_img=10)\n","\n","ddm.fit(\n","    train,\n","    epochs=EPOCHS,\n","    callbacks=[\n","        model_checkpoint_callback,\n","        tensorboard_callback,\n","        image_generator_callback,\n","    ],\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1EQjhIwz27i-YJPNQbwTPSRRYQO8PCZ8j"},"id":"LE62eON7qPhU","executionInfo":{"status":"error","timestamp":1731774313462,"user_tz":-540,"elapsed":325904,"user":{"displayName":"ᄋᄋ","userId":"18127923139488471666"}},"outputId":"7db67dbd-ff5f-4f00-8f3a-85f59604ea37"},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["!git clone https://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@github.com/JaeYunChung/pythonProject.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NJZUPeO5qPkv","executionInfo":{"status":"ok","timestamp":1731865314091,"user_tz":-540,"elapsed":287,"user":{"displayName":"ᄋᄋ","userId":"18127923139488471666"}},"outputId":"b1473695-10fd-4dfe-d3f7-d492760f410b"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'pythonProject' already exists and is not an empty directory.\n"]}]},{"cell_type":"code","source":["%cd ..\n","%ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"333SpwQ2N7aA","executionInfo":{"status":"ok","timestamp":1731865343875,"user_tz":-540,"elapsed":285,"user":{"displayName":"ᄋᄋ","userId":"18127923139488471666"}},"outputId":"8baf638e-64f3-4391-e1a3-3cba712d60d6"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34mpythonProject\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"]}]},{"cell_type":"code","source":["%cp /content/drive/MyDrive/Colab\\ Notebooks/diffusion_model.ipynb /content/pythonProject/"],"metadata":{"id":"2bspAXHoqPn5","executionInfo":{"status":"ok","timestamp":1731864666971,"user_tz":-540,"elapsed":1002,"user":{"displayName":"ᄋᄋ","userId":"18127923139488471666"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["%cd pythonProject/\n","%"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jTeZctLSKOfz","executionInfo":{"status":"ok","timestamp":1731864685525,"user_tz":-540,"elapsed":343,"user":{"displayName":"ᄋᄋ","userId":"18127923139488471666"}},"outputId":"db33519c-2b1e-4f9c-b66e-709e03ad50b7"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/pythonProject\n"]}]},{"cell_type":"code","source":["!git add *"],"metadata":{"id":"bIQb6c_XLei5","executionInfo":{"status":"ok","timestamp":1731864705774,"user_tz":-540,"elapsed":280,"user":{"displayName":"ᄋᄋ","userId":"18127923139488471666"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["!git commit -m \"diffusoin model commit\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SWQQuYfeLkuQ","executionInfo":{"status":"ok","timestamp":1731864748819,"user_tz":-540,"elapsed":513,"user":{"displayName":"ᄋᄋ","userId":"18127923139488471666"}},"outputId":"b03baf87-2981-43d5-c78a-b7c78b8120cb"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Author identity unknown\n","\n","*** Please tell me who you are.\n","\n","Run\n","\n","  git config --global user.email \"you@example.com\"\n","  git config --global user.name \"Your Name\"\n","\n","to set your account's default identity.\n","Omit --global to set the identity only in this repository.\n","\n","fatal: unable to auto-detect email address (got 'root@c0d717ee1109.(none)')\n"]}]},{"cell_type":"code","source":["!git config --global user.email \"wjdwodbs2334@gmail.com\"\n","!git config --global user.name \"JaeYunChung\""],"metadata":{"id":"ejhc3tj9Lt9X","executionInfo":{"status":"ok","timestamp":1731865101167,"user_tz":-540,"elapsed":398,"user":{"displayName":"ᄋᄋ","userId":"18127923139488471666"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["!git commit -m \"diffusion model commit\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cwb01tm4L6wP","executionInfo":{"status":"ok","timestamp":1731864817629,"user_tz":-540,"elapsed":288,"user":{"displayName":"ᄋᄋ","userId":"18127923139488471666"}},"outputId":"47d228fd-3bea-44d5-9ef6-8f26ff4f357f"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["[main (root-commit) 527d86e] diffusion model commit\n"," 1 file changed, 1 insertion(+)\n"," create mode 100644 diffusion_model.ipynb\n"]}]},{"cell_type":"code","source":["!git push"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sPuxQeauMAQ4","executionInfo":{"status":"ok","timestamp":1731865291267,"user_tz":-540,"elapsed":670,"user":{"displayName":"ᄋᄋ","userId":"18127923139488471666"}},"outputId":"4cbad82c-9fef-439a-bcfe-6d56dac26cb0"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: could not read Username for 'https://github.com': No such device or address\n"]}]}]}